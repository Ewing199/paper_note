1、参考文献
[1]张德良. 深度神经网络在中文语音识别系统中的实现 [D][D]. 北京交通大学, 2015.
[2]王海坤,潘嘉,刘聪.语音识别技术的研究进展与展望[J].电信科学,2018,34(02):1-11.
[3]古典. 语音识别中神经网络声学模型的说话人自适应研究[D].中国科学技术大学,2018.
[4]宋知用. MATLAB 在语音信号分析与合成中的应用[M]. 北京航空航天大学出版社, 2013.
[5]侯云飞. 中文语音关键词检出技术研究[D].南京理工大学,2017.

[5]Huang X, Acero A, Hon H W, et al. Spoken language processing: A guide to theory, algorithm, and system development[M]. Upper Saddle River: Prentice hall PTR, 2001.
[6]Rabiner L R. A tutorial on hidden Markov models and selected applications in speech recognition[J]. Proceedings of the IEEE, 1989, 77(2): 257-286.
[7]孙成立. 语音关键词识别技术的研究[D].北京邮电大学,2008.
[8]MOHAMED A R, DAHL G, HINTON G. Deep belief networks for phone recognition[EB]. 2009. 
[9]SAINATH T N,  KINGSBURY B, RAMABHADRAN  B, et al. Making  deep  belief  networks  effective  for  large  vocabulary continuous speech recognition[EB]. 2011. 
[10]MOHAMED  A,  DAHL  G E,  HINTON  G.  Acoustic  modeling using  deep  belief  networks[J].  IEEE Transactions  on  Audio, Speech, and Language Processing, 2012, 20(1): 14-22. 
[11]DAHL G E, YU D, DENG L, et al. Context-dependent pre-trained deep neural networks for large vocabulary speech recognition[J].IEEE Transactions on Audio, Speech, and  Lan-guage Processing, 2012, 20(1): 30-42. 
[12]HINTON G,  DENG L,  YU  D,  et  al. Deep neural networks for acoustic  modeling in speech recognition: the shared views of four research groups[J].  IEEE Signal  Processing Magazine, 2012, 29(6): 82-97. 
[13]王海坤, 潘嘉, 刘聪. 语音识别技术的研究进展与展望[J]. 电信科学, 2018, 34(2): 1-11.
[14]HOCHREITER S,SCHMIDHUBER J. Long short-term memory[J]. Neural Computation, 1997, 9(8): 1735-1780. 
[15]Yi J, Wen Z, Tao J, et al. CTC Regularized Model Adaptation for Improving LSTM RNN Based Multi-Accent Mandarin Speech Recognition[J]. Journal of Signal Processing Systems, 2018, 90(7): 985-997.
[16]Wang Z, Schultz T, Waibel A. Comparison of acoustic model adaptation techniques on non-native speech[C]//2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP'03). IEEE, 2003, 1: I-I.
[17]Liu Y, Fung P. Multi-accent Chinese speech recognition[C]//Ninth International Conference on Spoken Language Processing. 2006.
[18]Fung P, Liu Y. Effects and modeling of phonetic and acoustic confusions in accented speech[J]. the Journal of the Acoustical Society of America, 2005, 118(5): 3279-3293.
[19] Leading Group Office of Survey of Language Use in China (2006).In survey of language use in China. Beijing: Yu Wen Press (in Chinese).
[20]Davis S. B., & Mermelstein, P. (2013) Reliable Accent-Specific Unit Generation With Discriminative Dynamic Gaussian Mixture Selection for Multi-Accent Chinese Speech Recognition. IEEE Trans Acoustics Speech Signal Process, 21 (10), 2073–2084
[21]Vergyri, D., Lamel, L., & Gauvain, L. (2010). Automatic Speech Recognition of Multiple Accented English Data. In the Proceedings of Interspeech
[22] Ding, G. H. (2008). Phonetic Confusion Analysis and Robust Phone Set Generation for Shanghai-Accented Mandarin Speech Recognition. In the Proceedings of Interspeech.
[23]Fosler-Lussier, E., Amdal, I., & Kuo, H.-K. J. (2005). A Framework for Predicting Speech Recognition Errors. Speech Communication, 46(2), 153–170.
[24]Fosler-Lussier, E. (1999). Dynamic Pronunciation Models for Automatic Speech Recognition. Ph.D. dissertation, Int. Comput. Sci. Inst., Berkeley, CA, USA.
[25] Hain, T., & Woodland, P. C. (1999). Dynamic HMM Selection for Continuous Speech Recognition. In Proc. Eurospeech, pp. 1327–1330.
[26]V. Fisher et al. (1998). Speaker-Independent Upfront Dialect Adaptation in A Large Vocabulary Continuous Speech Recognition. In Proc. Int. Conf. Spoken Lang. Process.
[27]Elfeky M, Bastani M, Velez X, et al. Towards acoustic model unification across dialects[C]//2016 IEEE Spoken Language Technology Workshop (SLT). IEEE, 2016: 624-628.
[28]Yang X, Audhkhasi K, Rosenberg A, et al. Joint modeling of accents and acoustics for multi-accent speech recognition[C]//2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018: 1-5.
[29]Wang, Z., Schultz, T., & Waibel, A. (2003). Comparison of Acoustic Model Adaptation Techniques on Non-Native Speech. In ICASSP 2003. IEEE, pp. 540–543.
[30]Huang, Y., Yu, D., Liu, C. J., & Gong, Y. F. (2014). Multi-Accent Deep Neural Network Acoustic Model with Accent-Specific Top Layer Using the KLD Regularized Model Adaptation. In the Proceedings of Inter speech.
[31]Huang, J., Li, J., Yu, D., Deng, L., & Gong, Y. F. (2013). Cross Language Knowledge Transfer Using Multilingual Deep Neural Network With Shared Hidden Layers. In the Proceedings of the 2013 I.E. International Conference on Acoustics, Speech and
Signal Processing (ICASSP).
[32]Chen, M. M., Yang, Z. Y., Liang, J. Z., Li, Y. P., Liu, W. J. (2015). Improving Deep Neural Networks Based Multi-Accent Mandarin Speech Recognition Using I-Vectors and Accent-Specific Top layer. In the Proceedings of Interspeech.
[33]Sak, H., Senior, A., & Beaufays, F. (2014). Long Short-Term Memory Based Recurrent Neural Network Architectures for Large Vocabulary Speech Recognition. In the Proceedings of Interspeech.
[34] Yi, J., Ni, H., Wen, Z. H., & Tao, J. (2016). Improving BLSTM RNN Based Mandarin Speech Recognition Using Accent Dependent Bottleneck Features. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference
[35] Graves, A., Fernandez, S., Gomez, F., & Schmidhuber, J. (2006). Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks. In ICML, Pittsburgh, USA
[36]Graves, A., Mohamed, A., & Hinton, G. (2013). Speech Recognition With Deep Recurrent Neural Networks. In the Proceedings of the 2013 I.E. International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, pp. 6645–6649
[37] Graves, A., & Jaitly, N. (2014). Towards End-To-End Speech Recognition with Recurrent Neural Networks. In Proceedings of the 31st International Conference on Machine Learning (ICML-14), pp. 1764–1772.
[38] Hannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E., Prenger, R., Satheesh, S., Sengupta, S., Coates, A., et al. (2014). Deepspeech: Scaling up End-To-End Speech Recognition. arXiv preprint arXiv:1412.5567.
[39] Yu, D., Yao, K., Su, H., Li, G., & Seide, F. (2013). KL-Divergence Regularized Deep 
Neural Network Adaptation for Improved Large Vocabulary Speech Recognition. In the Proceedings of the 2013 I.E. International Conference on Acoustics, Speech and Signal
Processing (ICASSP).
[40]Dumoulin V, Perez E, Schucher N, et al. Feature-wise transformations[J]. Distill, 2018, 3(7): e11.
[41]Yoo S, Song I, Bengio Y. A Highly Adaptive Acoustic Model for Accurate Multi-dialect Speech Recognition[C]//ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019: 5716-5720.
[42]朱春山. 基于Kaldi的语音识别的研究[D].南京邮电大学,2018.


