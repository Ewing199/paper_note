1、参考文献
[1]张德良. 深度神经网络在中文语音识别系统中的实现 [D][D]. 北京交通大学, 2015.
[2]王海坤,潘嘉,刘聪.语音识别技术的研究进展与展望[J].电信科学,2018,34(02):1-11.
[3]古典. 语音识别中神经网络声学模型的说话人自适应研究[D].中国科学技术大学,2018.
[4]宋知用. MATLAB 在语音信号分析与合成中的应用[M]. 北京航空航天大学出版社, 2013.
[5]白静, 史燕燕, 薛珮芸, 等. 融合非线性幂函数和谱减法的 CFCC 特征提取[J]. 西安电子科技大学学报, 2019 (1): 17.
[6]SAINATH T N,  KINGSBURY B, RAMABHADRAN  B, et al. Making  deep  belief  networks  effective  for  large  vocabulary continuous speech recognition[EB]. 2011. 
[7]MOHAMED  A,  DAHL  G E,  HINTON  G.  Acoustic  modeling using  deep  belief  networks[J].  IEEE Transactions  on  Audio, Speech, and Language Processing, 2012, 20(1): 14-22. 
[8]侯云飞. 中文语音关键词检出技术研究[D].南京理工大学,2017.
[9]Muda L, Begam M, Elamvazuthi I. Voice recognition algorithms using mel frequency cepstral coefficient (MFCC) and dynamic time warping (DTW) techniques[J]. arXiv preprint arXiv:1003.4083, 2010.
[10]王坤, 刘鹤飞, 蒋成飞. 隐马尔可夫结构方程模型及其贝叶斯估计[J]. 数理统计与管理, 2018, 37(2): 272-279.
[11]MOHAMED A R, DAHL G, HINTON G. Deep belief networks for phone recognition[EB]. 2009. 
[12]DAHL G E, YU D, DENG L, et al. Context-dependent pre-trained deep neural networks for large vocabulary speech recognition[J].IEEE Transactions on Audio, Speech, and  Lan-guage Processing, 2012, 20(1): 30-42. 
[13]HINTON G,  DENG L,  YU  D,  et  al. Deep neural networks for acoustic  modeling in speech recognition: the shared views of four research groups[J].  IEEE Signal  Processing Magazine, 2012, 29(6): 82-97. 
[14]王海坤, 潘嘉, 刘聪. 语音识别技术的研究进展与展望[J]. 电信科学, 2018, 34(2): 1-11.
[++15]Graves, A., Mohamed, A., & Hinton, G. (2013). Speech Recognition With Deep Recurrent Neural Networks. In the Proceedings of the 2013 I.E. International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, pp. 6645–6649
[15]Miao Y, Gowayyed M, Metze F. EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding[C]//2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU). IEEE, 2015: 167-174.

[16]HOCHREITER S,SCHMIDHUBER J. Long short-term memory[J]. Neural Computation, 1997, 9(8): 1735-1780.
[17]黎煊,赵建,高云,刘望宏,雷明刚,谭鹤群.基于连续语音识别技术的猪连续咳嗽声识别[J].农业工程学报,2019,35(06):174-180.
[18]Yi J, Wen Z, Tao J, et al. CTC Regularized Model Adaptation for Improving LSTM RNN Based Multi-Accent Mandarin Speech Recognition[J]. Journal of Signal Processing Systems, 2018, 90(7): 985-997.
[19]王慧勇. 基于神经网络的多方言口音汉语语音识别系统研究[D].中国科学院深圳先进技术研究院,2014.
[20]Davis S. B., & Mermelstein, P. (2013) Reliable Accent-Specific Unit Generation With Discriminative Dynamic Gaussian Mixture Selection for Multi-Accent Chinese Speech Recognition. IEEE Trans Acoustics Speech Signal Process, 21 (10), 2073–2084
[21]Vergyri, D., Lamel, L., & Gauvain, L. (2010). Automatic Speech Recognition of Multiple Accented English Data. In the Proceedings of Interspeech
[22] Ding, G. H. (2008). Phonetic Confusion Analysis and Robust Phone Set Generation for Shanghai-Accented Mandarin Speech Recognition. In the Proceedings of Interspeech.
[23]Elfeky M, Bastani M, Velez X, et al. Towards acoustic model unification across dialects[C]//2016 IEEE Spoken Language Technology Workshop (SLT). IEEE, 2016: 624-628.
[24]Yang X, Audhkhasi K, Rosenberg A, et al. Joint modeling of accents and acoustics for multi-accent speech recognition[C]//2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018: 1-5.
[25]胡石,章毅,陈芳,陈心怡.基于HMM模型语音识别系统中声学模型的建立[J].通讯世界,2017(08):233-234.
[26]Huang, Y., Yu, D., Liu, C. J., & Gong, Y. F. (2014). Multi-Accent Deep Neural Network Acoustic Model with Accent-Specific Top Layer Using the KLD Regularized Model Adaptation. In the Proceedings of Inter speech.
[27]Huang, J., Li, J., Yu, D., Deng, L., & Gong, Y. F. (2013). Cross Language Knowledge Transfer Using Multilingual Deep Neural Network With Shared Hidden Layers. In the Proceedings of the 2013 I.E. International Conference on Acoustics, Speech and
Signal Processing (ICASSP).
[28]Chen, M. M., Yang, Z. Y., Liang, J. Z., Li, Y. P., Liu, W. J. (2015). Improving Deep Neural Networks Based Multi-Accent Mandarin Speech Recognition Using I-Vectors and Accent-Specific Top layer. In the Proceedings of Interspeech.
[29]Sak, H., Senior, A., & Beaufays, F. (2014). Long Short-Term Memory Based Recurrent Neural Network Architectures for Large Vocabulary Speech Recognition. In the Proceedings of Interspeech.
[30] Yi, J., Ni, H., Wen, Z. H., & Tao, J. (2016). Improving BLSTM RNN Based Mandarin Speech Recognition Using Accent Dependent Bottleneck Features. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference
[++30]Park J, Choi I, Boo Y, et al. Hierarchical Recurrent Neural Networks for Acoustic Modeling[J]. Proc. Interspeech 2018, 2018: 3728-3732.
[++31]Chan W, Jaitly N, Le Q, et al. Listen, attend and spell: A neural network for large vocabulary conversational speech recognition[C]//2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2016: 4960-4964.
[31] Yu, D., Yao, K., Su, H., Li, G., & Seide, F. (2013). KL-Divergence Regularized Deep 
Neural Network Adaptation for Improved Large Vocabulary Speech Recognition. In the Proceedings of the 2013 I.E. International Conference on Acoustics, Speech and Signal
Processing (ICASSP).
[32]Dumoulin V, Perez E, Schucher N, et al. Feature-wise transformations[J]. Distill, 2018, 3(7): e11.
[33]Yoo S, Song I, Bengio Y. A Highly Adaptive Acoustic Model for Accurate Multi-dialect Speech Recognition[C]//ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019: 5716-5720.
[34]朱春山. 基于Kaldi的语音识别的研究[D].南京邮电大学,2018.


[37] Graves, A., & Jaitly, N. (2014). Towards End-To-End Speech Recognition with Recurrent Neural Networks. In Proceedings of the 31st International Conference on Machine Learning (ICML-14), pp. 1764–1772.
[38] Hannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E., Prenger, R., Satheesh, S., Sengupta, S., Coates, A., et al. (2014). Deepspeech: Scaling up End-To-End Speech Recognition. arXiv preprint arXiv:1412.5567.





[16]Wang Z, Schultz T, Waibel A. Comparison of acoustic model adaptation techniques on non-native speech[C]//2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP'03). IEEE, 2003, 1: I-I.
[17]Liu Y, Fung P. Multi-accent Chinese speech recognition[C]//Ninth International Conference on Spoken Language Processing. 2006.
[18]Fung P, Liu Y. Effects and modeling of phonetic and acoustic confusions in accented speech[J]. the Journal of the Acoustical Society of America, 2005, 118(5): 3279-3293.






[29]Wang, Z., Schultz, T., & Waibel, A. (2003). Comparison of Acoustic Model Adaptation Techniques on Non-Native Speech. In ICASSP 2003. IEEE, pp. 540–543.




