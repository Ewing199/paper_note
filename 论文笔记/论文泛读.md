<attachment contentEditable="false" data-atts="%5B%5D" data-aid=".atts-a6157514-3734-4ddc-870c-53fb573658eb"></attachment>
# 论文泛读
提出问题-->解决方案-->创新点

## 1.基于深度学习的语音识别研究与应用---黎长江
应用场景：在线英语学习网站的口语评分系统
针对的问题：
解决方案：
达到效果：

## 2.语音关键词识别技术的研究---孙成立，博士论文
技术参考文章
### 1.基于垃圾模型的识别
实时性高，计算量小，速度快
提出问题：



## 3.广播电视语音识别现状与应用策略

## 4.Multi-Accent Chinese Speech Recognition（2006）
4.1 在标准语音决策树上使用一个辅助方言语音决策树
4.2 达到效果：吴语和广东话提升了识别
4.3 ==传统方案==是语音和声学模型上的变化，将语音单元扩展到特定的语音单元，造成问题，过多的语音集合争议发音会引起解码器的混淆，这种方法包括使用大量带重音的语音[2]对声学模型进行再训练;应用最大后验(MAP)或最大似然比(MLLR)自适应适应特定口音的特征[5,6];并利用判别训练对声学模型[7]进行细化
缺点：模型参数不可逆转的发生了变化，模型也失去了兼容其他口音的能力
4.4 本文方法：在汉语语音识别的基础上，利用不同的声场单元集合，进行声场模型重构，在不同的重音中，不同的重音变化由不同的重音单位来表示。通过对状态绑定三音子ASR系统的决策树合并，在状态级进行了声学模型重构。
**确定一个特定的Accent-units**
**构建辅助Accent-tree**（在我们的系统中，我们使用基于决策树的状态绑定来关联上下文的三音模型[9]。问题集的选择、决策树的大小和中心单元的选择是基于决策树状态绑定的关键问题）
**重建声学模型**（为每个特定的重音(如粤语或吴语)构造一组独立的辅助重音树。辅助重音树的结构、形状和大小对于每个重音都是独特的，即使在不同重音组之间共享中心单元时也是如此）
实验方法：**三种MFCC特征**，我们使用基于**HTK决策树**的状态绑定过程构建了12个包含5500个绑定状态的gaussiancomponent triphone模型，**个人构建吴语，广东话数据集**
4.5 读后：只是针对了吴语广东话建模，重点在于根据**口音构建决策树**方法有效，可以尝试查找源码和实现

	
## 5.Multi-Accent Deep Neural Network Acoustic Model with Accent-Specific Top Layer Using the KLD-Regularized Model Adaptation
5.1 提出了一种多口音的深层神经网络声学模型，该模型具有特殊的顶层和共享的底层隐藏层。特定于口音的顶层用于模拟不同口音的特定模式。共享的底层隐藏层允许在本机和重音模型之间最大限度地共享知识。在低于100k的语音识别上MMI sequence-level标准效率更高

5.2 传统方法：在此之前，重音语音ASR领域已经做了大量的工作，大致可以分为模型适应方法和词汇适应方法。**模型适应方法**通常比词汇适应方法更有效

5.3 本文方法：顶层用于模拟口音的独特语音模式，采用模型自适应技术，采用KL-divergence (KLD)正则化深度神经网络模型自适应方法训练针对具体客户的顶层
![title](https://i.loli.net/2019/05/29/5cee4ead571f568792.png)
**深度神经网络的顶层设计**
缺点：相对多语言神经网络的方法，数据量小，使用KLD-正则方法避免过拟合问题

5.4 KLD正则化模型自适应
查看文献
5.5 总结
采用顶层模型模拟口音，底层隐藏层与母语共享知识，这种方式由于他的计算效率很实用。然后实用KLD正则自适应模型适应顶层
**展望**：我们正在进行的研究课题包括基于神经元放电足迹的神经元选择性重音模型自适应、正则化权重可调模型自适应和正则化序列重音模型自适应。此外，我们正在研究另一种口音不变的深度学习方法，使用编码口音的额外神经网络输入来标准化语音的口音不同方面

## 6.MULTI-DIALECT SPEECH RECOGNITION WITH A SINGLE SEQUENCE-TO-SEQUENCE MODEL
6.1 序列到序列模型为构建语音识别系统提供了一个简单而优雅的解决方案，它折叠了一个典型系统的独立组件，即声学(AM)、发音(PM)和语言(LM)建模成一个单一的神经网络。本文提供了一个从Listen，attend和spell的序列到序列模型，探究用单一模型解决不同英语口音的识别问题。提出问题的思路：将所有方言数据汇聚到一个LAS系统中无法微调，所考虑使用方言的特定信息合并到一个模型中，通过在原始图形序列末尾插入方言符号来修改训练目标，并将方言信息的1-hot表示形式输入模型的各个层。（针对英语）
6.2 **现状**：不同类方言的差距大，针对某一种方言的系统不能推广到所有的方言模型中、不可避免地，多方言对ASR系统提出了挑战。如果每种方言都有足够的数据，通常的做法是独立对待每种方言[2,4,5]。或者，在方言资源稀缺的情况下，这些模型可以使用来自其他方言的数据进行增强[3,6]。通常的方法是定义一组通用的手机模型[7-9]，使用适当的参数共享[6]，并对其进行来自多种语言的数据训练，最终根据感兴趣的语言的数据进行调整[10-13]。[11, 14]开发了类似的神经网络模型，使用语言无关的特征提取和语言相关的语音分类器，进行训练.[12]进一步研究了一种以方言相关音素识别为次要任务的基于图元的多方言模型.基于高斯混合模型的[13]系统通常采用MLLR和MAP等自适应技术;但是对于基于神经网络的模型，通过对特定于方言的数据的持续训练来适应是有效的
6.3 本文方法：自适应方法[24,25]通常用于将特定于方言的信息整合到系统中。我们假设通过显式地向LAS模型提供方言信息，我们应该能够弥合方言独立模型和方言依赖模型之间的鸿沟。首先，我们通过在图形序列[26]中引入一个人工标记，在输出中使用方言信息。LAS模型既要学习字形预测，又要学习方言分类。其次，将方言信息作为输入向量输入系统。它既可以作为附加到每一层输入的额外信息向量，也可以作为集群自适应训练的权重系数[27]。该系统有几个吸引人的优点:1)简单:模型无需更改，只需添加更多的数据即可扩展到更多的方言;2)低资源方言的改进:在多方言系统中，大部分参数是所有方言隐式共享的，这就迫使模型在训练过程中跨方言泛化。
6.4 MULTI-DIALECT LAS MODEL：将方言信息作为输出目标、方言信息作为输入向量、方言信息作为聚类系数

## 7.A HIGHLY ADAPTIVE ACOUSTIC MODEL FOR ACCURATE MULTI-DIALECT SPEECH RECOGNITION
7.1 现状：虽然方言特有的声学模型在一般情况下表现良好，但当方言特有的数据很少且每种语言的方言数量都很大时，它们就不容易维护；处理多方言语音识别的有效方法是为每种方言训练一种方言专用调幅，尽管总的来说性能很好，但缺点是需要为每种方言维护单独的AM，这会增加操作成本。

7.2 提出的方法：我们提出的AM是基于方言信息及其内部表示动态调整的，这使得调幅具有高度的自适应能力，可以同时处理多种方言；我们还提出了一种简单而有效的训练方法来处理看不见的方言。
方法一：为多种方言构建单一AM的一种简单方法是根据多种方言的混合数据训练模型（是一种四路但表现不佳）








