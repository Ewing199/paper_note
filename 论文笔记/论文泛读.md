<attachment contentEditable="false" data-atts="%5B%5D" data-aid=".atts-a6157514-3734-4ddc-870c-53fb573658eb"></attachment>
# 论文泛读
提出问题-->解决方案-->创新点

## 1.基于深度学习的语音识别研究与应用---黎长江
应用场景：在线英语学习网站的口语评分系统
针对的问题：
解决方案：
达到效果：

## 2.语音关键词识别技术的研究---孙成立，博士论文
技术参考文章
### 1.基于垃圾模型的识别
实时性高，计算量小，速度快
提出问题：



## 3.广播电视语音识别现状与应用策略

## 4.Multi-Accent Chinese Speech Recognition（2006）
4.1 在标准语音决策树上使用一个辅助方言语音决策树
4.2 达到效果：吴语和广东话提升了识别
4.3 ==传统方案==是语音和声学模型上的变化，将语音单元扩展到特定的语音单元，造成问题，过多的语音集合争议发音会引起解码器的混淆，这种方法包括使用大量带重音的语音[2]对声学模型进行再训练;应用最大后验(MAP)或最大似然比(MLLR)自适应适应特定口音的特征[5,6];并利用判别训练对声学模型[7]进行细化
缺点：模型参数不可逆转的发生了变化，模型也失去了兼容其他口音的能力
4.4 本文方法：在汉语语音识别的基础上，利用不同的声场单元集合，进行声场模型重构，在不同的重音中，不同的重音变化由不同的重音单位来表示。通过对状态绑定三音子ASR系统的决策树合并，在状态级进行了声学模型重构。
**确定一个特定的Accent-units**
**构建辅助Accent-tree**（在我们的系统中，我们使用基于决策树的状态绑定来关联上下文的三音模型[9]。问题集的选择、决策树的大小和中心单元的选择是基于决策树状态绑定的关键问题）
**重建声学模型**（为每个特定的重音(如粤语或吴语)构造一组独立的辅助重音树。辅助重音树的结构、形状和大小对于每个重音都是独特的，即使在不同重音组之间共享中心单元时也是如此）
实验方法：**三种MFCC特征**，我们使用基于**HTK决策树**的状态绑定过程构建了12个包含5500个绑定状态的gaussiancomponent triphone模型，**个人构建吴语，广东话数据集**
4.5 读后：只是针对了吴语广东话建模，重点在于根据**口音构建决策树**方法有效，可以尝试查找源码和实现

	
## 5.Multi-Accent Deep Neural Network Acoustic Model with Accent-Specific Top Layer Using the KLD-Regularized Model Adaptation
5.1 提出了一种多口音的深层神经网络声学模型，该模型具有特殊的顶层和共享的底层隐藏层。特定于口音的顶层用于模拟不同口音的特定模式。共享的底层隐藏层允许在本机和重音模型之间最大限度地共享知识。在低于100k的语音识别上MMI sequence-level标准效率更高

5.2 传统方法：在此之前，重音语音ASR领域已经做了大量的工作，大致可以分为模型适应方法和词汇适应方法。**模型适应方法**通常比词汇适应方法更有效

5.3 本文方法：顶层用于模拟口音的独特语音模式，采用模型自适应技术，采用KL-divergence (KLD)正则化深度神经网络模型自适应方法训练针对具体客户的顶层
![title](https://i.loli.net/2019/05/29/5cee4ead571f568792.png)
**深度神经网络的顶层设计**
缺点：相对多语言神经网络的方法，数据量小，使用KLD-正则方法避免过拟合问题

5.4 KLD正则化模型自适应
查看文献
5.5 总结
采用顶层模型模拟口音，底层隐藏层与母语共享知识，这种方式由于











